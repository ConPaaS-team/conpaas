\label{sec:conclusion}



Nowadays cloud infrastructures offer a plethora of distinct hardware configurations for rent and price, we argued that autoscaling systems can use this diversity to better fulfill the SLA requirements without dramatically raising the operational cost. This has special importance for enterprises where a decrease in the user base led to a reduction in revenue, or for cloud providers where penalties paid due to SLO violations have a revenue impact. We proposed a novel autoscaling approach for cloud applications that provisions the most appropriate hardware configuration according to the customer requirements. This system benefits from cloud heterogeneity and online profiling techniques to find a scaling plan adapted to the QoS and current workload requirements. By considering factors such as SLO fulfillment or infrastructure cost, our system minimizes the performance degradations even under large and temporal workload variations. We implemented an autoscaling system that has been successfully deployed in multiple clouds. We evaluated our system in a realistic scenario showing the benefits by selecting a configuration that mitigates the performance degradations even under bursty workload. Nevertheless, these benefits could also be observed along the whole execution of a workload trace. In the future we plan to extend our system by supporting a bigger number of hardware configurations and by optimizing 
the dynamic load balancing mechanism. Similarly, we want to further study the financial impact of combining different hardware configurations.


% integrating a neural network forecasting model
% support for more types of instances.


%It is necessary to highlight the impotance of autoscaling systems that exploits the heterogeneity of the cloud infrastructures when provisioning applications.

%cheapest configuration doesn't have to be efficient. Tradittional system scale out and back using small instances.



