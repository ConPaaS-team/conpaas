
There is a wide literature on issues related to dynamic resource provisioning for cloud web applications. Different approaches present solutions based on queuing models~\cite{urgaonkar_agile_2008}, mathematical models~\cite{muppala_regression-based_2012} or even approaches using neural networks techniques~\cite{islam_empirical_2012}. However, most of these models require a deep understanding in mathematics or machine learning techniques which are not easily interpreted by non specialists. Besides the traffic in web applications is shaped by a combination of different factors such as diurnal/seasonal cycles that follows an irregular pattern, thus making extremely challenging the design and development of realistic and accurate provisioning mechanisms. 

These well-known drawbacks force to IaaS like Amazon EC2 and Windows Azure, or PaaS like RightScale and OpenShift,  to design simple trigger-based auto-scaling systems, instead of relying on approaches from academic research. Unfortunately, these scaling systems are imprecise and wasteful in terms of resource consumption and cost savings. % an easy target for flash crowds.

As a consequence, more relevant and realistic academic approaches have been proposed over the last years. \emph{Urgaonkar et al.}~\cite{urgaonkar_agile_2008} designed and implemented a predictive and reactive mechanism using a queuing model to decide the number of resources to be provisioned, and an admission control mechanism to face extreme workload variations. 
Even though the use of admission mechanisms enforce the performance requirements, it reduces the QoS of the service, and therefore affects user experience. A differnent approach for handling the worload variations was proposed by \emph{Muppala et al.}~\cite{muppala_regression-based_2012}, where offline training techniques were utilized to gather information about the resource requirements of the incoming requests, and thereby to improve the accuracy of the scaling decisions. In the same vein, DejaVu~\cite{vasic_dejavu_2012} and CBMG~\cite{roy_efficient_2011} built similar mechanisms to classify the workload need by analyzing recent traffic spikes or the customer behavior. However, these approaches require additional resources to identify the workload requirements, and an exhaustive knowlegde of the deployed applications; thus preventing its integration in existing auto scaling systems.

%As we mentioned, offline and online profiling are promising techniques when handling unpredictable and temporal burstly workloads in web applications. 

As a proposal closely related to ours, \emph{Ghanbari et al.}~\cite{ghanbari_exploring_2011} designed an auto scaling system using control theoretic and rules-based models. The authors claimed for simpler provisioning mechanisms in comparison with the sophisticated academic approaches. However, factors such as resource heterogeneity were not addressed in this system.  

%Regarding the management of flash crowds~\cite{zhang_resilient_2009}, a proactive application %workload manager was designed to separate the user requests between two groups of servers:  %one  named  'base workload'  referred to the smaller and smoother variations in the workload; %and the other 'tresspassing' referred to the temporal burstly workloads caused by flash crowds. %To do this, the authors attempt to divide the data items into popular and less popular, and %place them in the right group of servers. Even tough a realistic evaluation was conducted on %Amazon EC2 utilizing real traces (Yahoo video streaming), authors do not explain in details how %the dynamic resource provisioning is done. 

%An evaluation using real-traces on a homogeneous infrastructures shows the benefits of this approach when handling flash crowds. 
%Unfortunately, its admission control mechanism incurs into sporadic SLA violations ( if the server utilization exceed a pre-defined threshold) reducing the QoS of the service, and therefore affecting user experience. 



% Workloads follow irregular patterns including “ﬂash crowds".




%Similarly to the previous work, \cite{wang_appraise:_2009} extended queuing models and %transaction mix models to design a predictive and reactive provisioning system. To model the %application performance, they integrated proactive control and feedback control methods that %dynamically adjusted the CPU capacity allocated to servers. This work only considered SLA %constraints at the system-level, while others constraints at application-specific level such as %response time and request rate were not taken into consideration. Besides, an evaluation of %CPU variations on a homogeneous infrastructure, when processing traces from a non real-world %application, lack arguments to valid its approach.

%control and dynamic provisioning components in addition to the load balancing algorithm. It applies admission control to make sure ﬂash crowd requests
%will not overload the provisioned server pool by dropping requests, and uses queuing-model based dynamic provisioning technology.


% It is slow to workload changes and not eﬀective at handling complex load
%patterns experienced in practice. Besides, over peak load reactive dynamic provisioning typically does no more than overprovisioning over one computing resource, while %the provisioning over other resources including storage and networking is not explicitly addressed or optimized.


%Recently, in  \cite{kaviani_profiling-as--service:_2011}, profiling-based techniques have been %utilized for managing the tradeofff between performance overload, and cost savings for %dynamic resource provisioning. The authors replicate at runtime a regular server hosting an %application, with a new server with profiling instrumentation. Their experimental results show %how profiling techniques can be included in a resource provisioning system, without causing %important response time delays or throughput alterations in comparison with non-profiling %provisioning. As we mentioned in Section~\ref{experiments}, profiling techniques can report %more benefits than  performance degradations or expenses.
